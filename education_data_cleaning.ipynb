{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Colombian Education Data: Cleaning and Feature Engineering\n",
    "\n",
    "**Objective:** Clean the raw dataset of Colombian educational statistics, handle missing values, and engineer predictive features for a Random Forest Regressor targeting the `DESERCIÓN` (Dropout Rate).\n",
    "\n",
    "**Author:** Senior Data Scientist\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Import Libraries and Load Data\n",
    "\n",
    "First, we import the necessary libraries (`pandas` and `numpy`) and load the raw dataset from `Colombia_education_departamento.csv` into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "Initial shape: (462, 37)\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AÑO</th>\n",
       "      <th>CÓDIGO_DEPARTAMENTO</th>\n",
       "      <th>DEPARTAMENTO</th>\n",
       "      <th>POBLACIÓN_5_16</th>\n",
       "      <th>TASA_MATRICULACIÓN_5_16</th>\n",
       "      <th>COBERTURA_NETA</th>\n",
       "      <th>COBERTURA_NETA_TRANSICIÓN</th>\n",
       "      <th>COBERTURA_NETA_PRIMARIA</th>\n",
       "      <th>COBERTURA_NETA_SECUNDARIA</th>\n",
       "      <th>COBERTURA_NETA_MEDIA</th>\n",
       "      <th>...</th>\n",
       "      <th>REPROBACIÓN</th>\n",
       "      <th>REPROBACIÓN_TRANSICIÓN</th>\n",
       "      <th>REPROBACIÓN_PRIMARIA</th>\n",
       "      <th>REPROBACIÓN_SECUNDARIA</th>\n",
       "      <th>REPROBACIÓN_MEDIA</th>\n",
       "      <th>REPITENCIA</th>\n",
       "      <th>REPITENCIA_TRANSICIÓN</th>\n",
       "      <th>REPITENCIA_PRIMARIA</th>\n",
       "      <th>REPITENCIA_SECUNDARIA</th>\n",
       "      <th>REPITENCIA_MEDIA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011</td>\n",
       "      <td>5</td>\n",
       "      <td>Antioquia</td>\n",
       "      <td>1288473</td>\n",
       "      <td>94.01%</td>\n",
       "      <td>93.85%</td>\n",
       "      <td>70.28%</td>\n",
       "      <td>94.12%</td>\n",
       "      <td>75.68%</td>\n",
       "      <td>44.37%</td>\n",
       "      <td>...</td>\n",
       "      <td>2.06%</td>\n",
       "      <td>0.07%</td>\n",
       "      <td>94.56%</td>\n",
       "      <td>2.54%</td>\n",
       "      <td>2.96%</td>\n",
       "      <td>4.25%</td>\n",
       "      <td>0.07%</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>5.27%</td>\n",
       "      <td>1.68%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "      <td>Atlántico</td>\n",
       "      <td>523935</td>\n",
       "      <td>99.32%</td>\n",
       "      <td>99.05%</td>\n",
       "      <td>50.59%</td>\n",
       "      <td>98.93%</td>\n",
       "      <td>80.22%</td>\n",
       "      <td>50.17%</td>\n",
       "      <td>...</td>\n",
       "      <td>0.54%</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>96.49%</td>\n",
       "      <td>0.67%</td>\n",
       "      <td>0.75%</td>\n",
       "      <td>1.82%</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>1.77%</td>\n",
       "      <td>2.18%</td>\n",
       "      <td>0.88%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011</td>\n",
       "      <td>11</td>\n",
       "      <td>Bogotá, D.C.</td>\n",
       "      <td>1479334</td>\n",
       "      <td>90.7%</td>\n",
       "      <td>90.29%</td>\n",
       "      <td>68.63%</td>\n",
       "      <td>86.99%</td>\n",
       "      <td>84.7%</td>\n",
       "      <td>55.01%</td>\n",
       "      <td>...</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>94.69%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>3.23%</td>\n",
       "      <td>0%</td>\n",
       "      <td>2.3%</td>\n",
       "      <td>5.11%</td>\n",
       "      <td>2.57%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>13</td>\n",
       "      <td>Bolívar</td>\n",
       "      <td>496676</td>\n",
       "      <td>91.57%</td>\n",
       "      <td>91.4%</td>\n",
       "      <td>59.74%</td>\n",
       "      <td>90.81%</td>\n",
       "      <td>67.34%</td>\n",
       "      <td>39.17%</td>\n",
       "      <td>...</td>\n",
       "      <td>2.1%</td>\n",
       "      <td>0.46%</td>\n",
       "      <td>95.48%</td>\n",
       "      <td>2.75%</td>\n",
       "      <td>3.67%</td>\n",
       "      <td>4.43%</td>\n",
       "      <td>0.46%</td>\n",
       "      <td>4.44%</td>\n",
       "      <td>5.37%</td>\n",
       "      <td>2.28%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011</td>\n",
       "      <td>15</td>\n",
       "      <td>Boyacá</td>\n",
       "      <td>300501</td>\n",
       "      <td>86.16%</td>\n",
       "      <td>86.11%</td>\n",
       "      <td>63.36%</td>\n",
       "      <td>82.5%</td>\n",
       "      <td>74.65%</td>\n",
       "      <td>49.09%</td>\n",
       "      <td>...</td>\n",
       "      <td>2.73%</td>\n",
       "      <td>0.17%</td>\n",
       "      <td>96.1%</td>\n",
       "      <td>4.31%</td>\n",
       "      <td>3.26%</td>\n",
       "      <td>2.62%</td>\n",
       "      <td>0.17%</td>\n",
       "      <td>1.9%</td>\n",
       "      <td>4.19%</td>\n",
       "      <td>1.55%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    AÑO  CÓDIGO_DEPARTAMENTO  DEPARTAMENTO  POBLACIÓN_5_16  \\\n",
       "0  2011                    5     Antioquia         1288473   \n",
       "1  2011                    8     Atlántico          523935   \n",
       "2  2011                   11  Bogotá, D.C.         1479334   \n",
       "3  2011                   13       Bolívar          496676   \n",
       "4  2011                   15        Boyacá          300501   \n",
       "\n",
       "  TASA_MATRICULACIÓN_5_16 COBERTURA_NETA COBERTURA_NETA_TRANSICIÓN  \\\n",
       "0                  94.01%         93.85%                    70.28%   \n",
       "1                  99.32%         99.05%                    50.59%   \n",
       "2                   90.7%         90.29%                    68.63%   \n",
       "3                  91.57%          91.4%                    59.74%   \n",
       "4                  86.16%         86.11%                    63.36%   \n",
       "\n",
       "  COBERTURA_NETA_PRIMARIA COBERTURA_NETA_SECUNDARIA COBERTURA_NETA_MEDIA  ...  \\\n",
       "0                  94.12%                    75.68%               44.37%  ...   \n",
       "1                  98.93%                    80.22%               50.17%  ...   \n",
       "2                  86.99%                     84.7%               55.01%  ...   \n",
       "3                  90.81%                    67.34%               39.17%  ...   \n",
       "4                   82.5%                    74.65%               49.09%  ...   \n",
       "\n",
       "  REPROBACIÓN REPROBACIÓN_TRANSICIÓN REPROBACIÓN_PRIMARIA  \\\n",
       "0       2.06%                  0.07%               94.56%   \n",
       "1       0.54%                  0.12%               96.49%   \n",
       "2          0%                     0%               94.69%   \n",
       "3        2.1%                  0.46%               95.48%   \n",
       "4       2.73%                  0.17%                96.1%   \n",
       "\n",
       "  REPROBACIÓN_SECUNDARIA REPROBACIÓN_MEDIA  REPITENCIA  REPITENCIA_TRANSICIÓN  \\\n",
       "0                  2.54%             2.96%       4.25%                  0.07%   \n",
       "1                  0.67%             0.75%       1.82%                  0.12%   \n",
       "2                     0%                0%       3.23%                     0%   \n",
       "3                  2.75%             3.67%       4.43%                  0.46%   \n",
       "4                  4.31%             3.26%       2.62%                  0.17%   \n",
       "\n",
       "  REPITENCIA_PRIMARIA REPITENCIA_SECUNDARIA REPITENCIA_MEDIA  \n",
       "0               4.56%                 5.27%            1.68%  \n",
       "1               1.77%                 2.18%            0.88%  \n",
       "2                2.3%                 5.11%            2.57%  \n",
       "3               4.44%                 5.37%            2.28%  \n",
       "4                1.9%                 4.19%            1.55%  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "try:\n",
    "    df = pd.read_csv('Colombia_education_departamento.csv')\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "    print(f\"Initial shape: {df.shape}\")\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    display(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'Colombia_education_departamento.csv' not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Data Cleaning & Typing\n",
    "\n",
    "In this step, we perform two critical cleaning operations:\n",
    "1.  **String Cleanup:** We identify all columns that contain string representations of percentages (e.g., \"93.85%\"). We then strip the '%' symbol, handle decimal commas, and convert these columns to a proper floating-point numeric type for calculations.\n",
    "2.  **Corrupt Data Removal:** The `SEDES_CONECTADAS_A_INTERNET` column is known to have severe data quality issues and will be dropped entirely as per the project requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Cleaning data and fixing types ---\n",
      "Found 31 columns with '%' to convert: ['TASA_MATRICULACIÓN_5_16', 'COBERTURA_NETA', 'COBERTURA_NETA_TRANSICIÓN', 'COBERTURA_NETA_PRIMARIA', 'COBERTURA_NETA_SECUNDARIA']...\n",
      "\n",
      "Converted percentage columns to numeric type.\n",
      "Dropped 'SEDES_CONECTADAS_A_INTERNET' column.\n",
      "\n",
      "Data cleaning and typing complete.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AÑO</th>\n",
       "      <th>CÓDIGO_DEPARTAMENTO</th>\n",
       "      <th>DEPARTAMENTO</th>\n",
       "      <th>POBLACIÓN_5_16</th>\n",
       "      <th>TASA_MATRICULACIÓN_5_16</th>\n",
       "      <th>COBERTURA_NETA</th>\n",
       "      <th>COBERTURA_NETA_TRANSICIÓN</th>\n",
       "      <th>COBERTURA_NETA_PRIMARIA</th>\n",
       "      <th>COBERTURA_NETA_SECUNDARIA</th>\n",
       "      <th>COBERTURA_NETA_MEDIA</th>\n",
       "      <th>...</th>\n",
       "      <th>REPROBACIÓN</th>\n",
       "      <th>REPROBACIÓN_TRANSICIÓN</th>\n",
       "      <th>REPROBACIÓN_PRIMARIA</th>\n",
       "      <th>REPROBACIÓN_SECUNDARIA</th>\n",
       "      <th>REPROBACIÓN_MEDIA</th>\n",
       "      <th>REPITENCIA</th>\n",
       "      <th>REPITENCIA_TRANSICIÓN</th>\n",
       "      <th>REPITENCIA_PRIMARIA</th>\n",
       "      <th>REPITENCIA_SECUNDARIA</th>\n",
       "      <th>REPITENCIA_MEDIA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011</td>\n",
       "      <td>5</td>\n",
       "      <td>Antioquia</td>\n",
       "      <td>1288473</td>\n",
       "      <td>94.01</td>\n",
       "      <td>93.85</td>\n",
       "      <td>70.28</td>\n",
       "      <td>94.12</td>\n",
       "      <td>75.68</td>\n",
       "      <td>44.37</td>\n",
       "      <td>...</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.07</td>\n",
       "      <td>94.56</td>\n",
       "      <td>2.54</td>\n",
       "      <td>2.96</td>\n",
       "      <td>4.25</td>\n",
       "      <td>0.07</td>\n",
       "      <td>4.56</td>\n",
       "      <td>5.27</td>\n",
       "      <td>1.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "      <td>Atlántico</td>\n",
       "      <td>523935</td>\n",
       "      <td>99.32</td>\n",
       "      <td>99.05</td>\n",
       "      <td>50.59</td>\n",
       "      <td>98.93</td>\n",
       "      <td>80.22</td>\n",
       "      <td>50.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.12</td>\n",
       "      <td>96.49</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.82</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.77</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011</td>\n",
       "      <td>11</td>\n",
       "      <td>Bogotá, D.C.</td>\n",
       "      <td>1479334</td>\n",
       "      <td>90.70</td>\n",
       "      <td>90.29</td>\n",
       "      <td>68.63</td>\n",
       "      <td>86.99</td>\n",
       "      <td>84.70</td>\n",
       "      <td>55.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>94.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.30</td>\n",
       "      <td>5.11</td>\n",
       "      <td>2.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>13</td>\n",
       "      <td>Bolívar</td>\n",
       "      <td>496676</td>\n",
       "      <td>91.57</td>\n",
       "      <td>91.40</td>\n",
       "      <td>59.74</td>\n",
       "      <td>90.81</td>\n",
       "      <td>67.34</td>\n",
       "      <td>39.17</td>\n",
       "      <td>...</td>\n",
       "      <td>2.10</td>\n",
       "      <td>0.46</td>\n",
       "      <td>95.48</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.67</td>\n",
       "      <td>4.43</td>\n",
       "      <td>0.46</td>\n",
       "      <td>4.44</td>\n",
       "      <td>5.37</td>\n",
       "      <td>2.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011</td>\n",
       "      <td>15</td>\n",
       "      <td>Boyacá</td>\n",
       "      <td>300501</td>\n",
       "      <td>86.16</td>\n",
       "      <td>86.11</td>\n",
       "      <td>63.36</td>\n",
       "      <td>82.50</td>\n",
       "      <td>74.65</td>\n",
       "      <td>49.09</td>\n",
       "      <td>...</td>\n",
       "      <td>2.73</td>\n",
       "      <td>0.17</td>\n",
       "      <td>96.10</td>\n",
       "      <td>4.31</td>\n",
       "      <td>3.26</td>\n",
       "      <td>2.62</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.90</td>\n",
       "      <td>4.19</td>\n",
       "      <td>1.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    AÑO  CÓDIGO_DEPARTAMENTO  DEPARTAMENTO  POBLACIÓN_5_16  \\\n",
       "0  2011                    5     Antioquia         1288473   \n",
       "1  2011                    8     Atlántico          523935   \n",
       "2  2011                   11  Bogotá, D.C.         1479334   \n",
       "3  2011                   13       Bolívar          496676   \n",
       "4  2011                   15        Boyacá          300501   \n",
       "\n",
       "   TASA_MATRICULACIÓN_5_16  COBERTURA_NETA  COBERTURA_NETA_TRANSICIÓN  \\\n",
       "0                    94.01           93.85                      70.28   \n",
       "1                    99.32           99.05                      50.59   \n",
       "2                    90.70           90.29                      68.63   \n",
       "3                    91.57           91.40                      59.74   \n",
       "4                    86.16           86.11                      63.36   \n",
       "\n",
       "   COBERTURA_NETA_PRIMARIA  COBERTURA_NETA_SECUNDARIA  COBERTURA_NETA_MEDIA  \\\n",
       "0                    94.12                      75.68                 44.37   \n",
       "1                    98.93                      80.22                 50.17   \n",
       "2                    86.99                      84.70                 55.01   \n",
       "3                    90.81                      67.34                 39.17   \n",
       "4                    82.50                      74.65                 49.09   \n",
       "\n",
       "   ...  REPROBACIÓN  REPROBACIÓN_TRANSICIÓN  REPROBACIÓN_PRIMARIA  \\\n",
       "0  ...         2.06                    0.07                 94.56   \n",
       "1  ...         0.54                    0.12                 96.49   \n",
       "2  ...         0.00                    0.00                 94.69   \n",
       "3  ...         2.10                    0.46                 95.48   \n",
       "4  ...         2.73                    0.17                 96.10   \n",
       "\n",
       "   REPROBACIÓN_SECUNDARIA  REPROBACIÓN_MEDIA  REPITENCIA  \\\n",
       "0                    2.54               2.96        4.25   \n",
       "1                    0.67               0.75        1.82   \n",
       "2                    0.00               0.00        3.23   \n",
       "3                    2.75               3.67        4.43   \n",
       "4                    4.31               3.26        2.62   \n",
       "\n",
       "   REPITENCIA_TRANSICIÓN  REPITENCIA_PRIMARIA  REPITENCIA_SECUNDARIA  \\\n",
       "0                   0.07                 4.56                   5.27   \n",
       "1                   0.12                 1.77                   2.18   \n",
       "2                   0.00                 2.30                   5.11   \n",
       "3                   0.46                 4.44                   5.37   \n",
       "4                   0.17                 1.90                   4.19   \n",
       "\n",
       "   REPITENCIA_MEDIA  \n",
       "0              1.68  \n",
       "1              0.88  \n",
       "2              2.57  \n",
       "3              2.28  \n",
       "4              1.55  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"--- Step 1: Cleaning data and fixing types ---\")\n",
    "\n",
    "# Identify columns with percentage strings\n",
    "percent_cols = [col for col in df.columns if df[col].dtype == 'object' and df[col].str.contains('%', na=False).any()]\n",
    "\n",
    "print(f\"Found {len(percent_cols)} columns with '%' to convert: {percent_cols[:5]}...\")  # Show first 5\n",
    "\n",
    "# Clean and convert these columns to numeric\n",
    "for col in percent_cols:\n",
    "    df[col] = df[col].str.replace('%', '', regex=False).str.replace(',', '.', regex=False)\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "print(\"\\nConverted percentage columns to numeric type.\")\n",
    "\n",
    "# Drop the corrupt 'SEDES_CONECTADAS_A_INTERNET' column\n",
    "if 'SEDES_CONECTADAS_A_INTERNET' in df.columns:\n",
    "    df = df.drop(columns=['SEDES_CONECTADAS_A_INTERNET'])\n",
    "    print(\"Dropped 'SEDES_CONECTADAS_A_INTERNET' column.\")\n",
    "\n",
    "print(\"\\nData cleaning and typing complete.\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Smart Imputation (Handling Nulls)\n",
    "\n",
    "Missing data can break our model. We'll handle it intelligently:\n",
    "1.  **Target Variable (`DESERCIÓN`):** Any row where the target variable is missing is unusable for training. We will drop these rows.\n",
    "2.  **`TAMAÑO_PROMEDIO_DE_GRUPO` (Class Density):** This is a potentially high-value feature. Instead of dropping rows, we will impute missing values using the **median** value for that specific department (`CÓDIGO_DEPARTAMENTO`). If a department has no data at all for this column, we'll use the global median as a fallback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 rows with missing target (DESERCIÓN).\n",
      "Found 56 rows with impossible class sizes (e.g., >100). Fixing scaling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/w6gmqgrs64b5x2c7vhrcz92w0000gr/T/ipykernel_28953/3626047835.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['classroom_density'].fillna(global_median, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "initial_rows = len(df)\n",
    "df.dropna(subset=['DESERCIÓN'], inplace=True)\n",
    "print(f\"Dropped {initial_rows - len(df)} rows with missing target (DESERCIÓN).\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. SMART IMPUTATION & OUTLIER FIX (Class Density)\n",
    "# ---------------------------------------------------------\n",
    "# Rename for easier typing\n",
    "if 'TAMAÑO_PROMEDIO_DE_GRUPO' in df.columns:\n",
    "    df.rename(columns={'TAMAÑO_PROMEDIO_DE_GRUPO': 'classroom_density'}, inplace=True)\n",
    "\n",
    "# A. Impute missing values using the Median of THAT Department\n",
    "# (Better than global average because rural vs urban classes differ size)\n",
    "df['classroom_density'] = df.groupby('CÓDIGO_DEPARTAMENTO')['classroom_density'].transform(\n",
    "    lambda x: x.fillna(x.median())\n",
    ")\n",
    "# Fallback: If a department has NO data at all, use global median\n",
    "global_median = df['classroom_density'].median()\n",
    "df['classroom_density'].fillna(global_median, inplace=True)\n",
    "\n",
    "# B. THE CRITICAL FIX: The \"Comma vs Dot\" Error\n",
    "# Problem: Values like 30588.00 should be 30.588\n",
    "# Logic: Any class size > 100 is physically impossible. Divide by 1000.\n",
    "outlier_mask = df['classroom_density'] > 100\n",
    "num_outliers = outlier_mask.sum()\n",
    "if num_outliers > 0:\n",
    "    print(f\"Found {num_outliers} rows with impossible class sizes (e.g., >100). Fixing scaling...\")\n",
    "    df.loc[outlier_mask, 'classroom_density'] = df.loc[outlier_mask, 'classroom_density'] / 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Feature Engineering (\"The Golden Features\")\n",
    "\n",
    "Now, we create powerful new predictors based on domain knowledge:\n",
    "1.  **`over_age_gap`**: Calculated as `COBERTURA_BRUTA - COBERTURA_NETA`. This feature captures the percentage of students who are over-age for their grade level, a strong indicator of social risk and potential dropout.\n",
    "2.  **`repitencia_lag_1`**: Dropout is often preceded by academic failure. This feature captures the repetition rate from the *previous year* for the same department. We sort the data by department and year to create this lagged feature.\n",
    "3.  **`classroom_density`**: We rename the cleaned `TAMAÑO_PROMEDIO_DE_GRUPO` column to a more intuitive name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 3: Engineering new features ---\n",
      "Created 'over_age_gap' feature.\n",
      "  Mean: 12.26, Std: 3.43\n",
      "Created 'repitencia_lag_1' (lagged repetition) feature.\n",
      "  NaN values created: 33 (first year of each department)\n",
      "\n",
      "Feature engineering complete.\n",
      "\n",
      "Sample of new features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AÑO</th>\n",
       "      <th>DEPARTAMENTO</th>\n",
       "      <th>over_age_gap</th>\n",
       "      <th>REPITENCIA</th>\n",
       "      <th>repitencia_lag_1</th>\n",
       "      <th>classroom_density</th>\n",
       "      <th>DESERCIÓN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011</td>\n",
       "      <td>Antioquia</td>\n",
       "      <td>12.96</td>\n",
       "      <td>4.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.470</td>\n",
       "      <td>3.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2012</td>\n",
       "      <td>Antioquia</td>\n",
       "      <td>13.15</td>\n",
       "      <td>1.93</td>\n",
       "      <td>4.25</td>\n",
       "      <td>27.960</td>\n",
       "      <td>4.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2013</td>\n",
       "      <td>Antioquia</td>\n",
       "      <td>13.76</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.93</td>\n",
       "      <td>52.720</td>\n",
       "      <td>3.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2014</td>\n",
       "      <td>Antioquia</td>\n",
       "      <td>13.05</td>\n",
       "      <td>2.09</td>\n",
       "      <td>1.57</td>\n",
       "      <td>31.170</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>2015</td>\n",
       "      <td>Antioquia</td>\n",
       "      <td>13.35</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2.09</td>\n",
       "      <td>30.390</td>\n",
       "      <td>3.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>2016</td>\n",
       "      <td>Antioquia</td>\n",
       "      <td>13.64</td>\n",
       "      <td>3.02</td>\n",
       "      <td>2.83</td>\n",
       "      <td>30.588</td>\n",
       "      <td>4.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2017</td>\n",
       "      <td>Antioquia</td>\n",
       "      <td>12.15</td>\n",
       "      <td>6.52</td>\n",
       "      <td>3.02</td>\n",
       "      <td>31.728</td>\n",
       "      <td>4.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>2018</td>\n",
       "      <td>Antioquia</td>\n",
       "      <td>14.28</td>\n",
       "      <td>3.13</td>\n",
       "      <td>6.52</td>\n",
       "      <td>31.170</td>\n",
       "      <td>3.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>2019</td>\n",
       "      <td>Antioquia</td>\n",
       "      <td>13.74</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.13</td>\n",
       "      <td>31.170</td>\n",
       "      <td>4.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>2020</td>\n",
       "      <td>Antioquia</td>\n",
       "      <td>12.76</td>\n",
       "      <td>6.48</td>\n",
       "      <td>3.19</td>\n",
       "      <td>31.170</td>\n",
       "      <td>2.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>2021</td>\n",
       "      <td>Antioquia</td>\n",
       "      <td>12.24</td>\n",
       "      <td>5.84</td>\n",
       "      <td>6.48</td>\n",
       "      <td>31.170</td>\n",
       "      <td>4.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2022</td>\n",
       "      <td>Antioquia</td>\n",
       "      <td>11.52</td>\n",
       "      <td>6.49</td>\n",
       "      <td>5.84</td>\n",
       "      <td>31.170</td>\n",
       "      <td>4.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>2023</td>\n",
       "      <td>Antioquia</td>\n",
       "      <td>10.72</td>\n",
       "      <td>9.69</td>\n",
       "      <td>6.49</td>\n",
       "      <td>31.170</td>\n",
       "      <td>4.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>2024</td>\n",
       "      <td>Antioquia</td>\n",
       "      <td>10.14</td>\n",
       "      <td>9.26</td>\n",
       "      <td>9.69</td>\n",
       "      <td>31.170</td>\n",
       "      <td>3.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>Atlántico</td>\n",
       "      <td>8.83</td>\n",
       "      <td>1.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.420</td>\n",
       "      <td>2.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2012</td>\n",
       "      <td>Atlántico</td>\n",
       "      <td>8.96</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.82</td>\n",
       "      <td>22.460</td>\n",
       "      <td>3.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2013</td>\n",
       "      <td>Atlántico</td>\n",
       "      <td>9.36</td>\n",
       "      <td>1.66</td>\n",
       "      <td>0.80</td>\n",
       "      <td>29.460</td>\n",
       "      <td>3.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2014</td>\n",
       "      <td>Atlántico</td>\n",
       "      <td>8.07</td>\n",
       "      <td>1.82</td>\n",
       "      <td>1.66</td>\n",
       "      <td>23.570</td>\n",
       "      <td>3.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2015</td>\n",
       "      <td>Atlántico</td>\n",
       "      <td>7.46</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.82</td>\n",
       "      <td>26.270</td>\n",
       "      <td>1.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>2016</td>\n",
       "      <td>Atlántico</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.69</td>\n",
       "      <td>27.781</td>\n",
       "      <td>2.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AÑO DEPARTAMENTO  over_age_gap  REPITENCIA  repitencia_lag_1  \\\n",
       "0    2011    Antioquia         12.96        4.25               NaN   \n",
       "33   2012    Antioquia         13.15        1.93              4.25   \n",
       "66   2013    Antioquia         13.76        1.57              1.93   \n",
       "99   2014    Antioquia         13.05        2.09              1.57   \n",
       "132  2015    Antioquia         13.35        2.83              2.09   \n",
       "165  2016    Antioquia         13.64        3.02              2.83   \n",
       "198  2017    Antioquia         12.15        6.52              3.02   \n",
       "231  2018    Antioquia         14.28        3.13              6.52   \n",
       "264  2019    Antioquia         13.74        3.19              3.13   \n",
       "297  2020    Antioquia         12.76        6.48              3.19   \n",
       "330  2021    Antioquia         12.24        5.84              6.48   \n",
       "363  2022    Antioquia         11.52        6.49              5.84   \n",
       "396  2023    Antioquia         10.72        9.69              6.49   \n",
       "429  2024    Antioquia         10.14        9.26              9.69   \n",
       "1    2011    Atlántico          8.83        1.82               NaN   \n",
       "34   2012    Atlántico          8.96        0.80              1.82   \n",
       "67   2013    Atlántico          9.36        1.66              0.80   \n",
       "100  2014    Atlántico          8.07        1.82              1.66   \n",
       "133  2015    Atlántico          7.46        1.69              1.82   \n",
       "166  2016    Atlántico          8.67        1.23              1.69   \n",
       "\n",
       "     classroom_density  DESERCIÓN  \n",
       "0               27.470       3.97  \n",
       "33              27.960       4.01  \n",
       "66              52.720       3.57  \n",
       "99              31.170       2.33  \n",
       "132             30.390       3.82  \n",
       "165             30.588       4.47  \n",
       "198             31.728       4.15  \n",
       "231             31.170       3.97  \n",
       "264             31.170       4.02  \n",
       "297             31.170       2.30  \n",
       "330             31.170       4.81  \n",
       "363             31.170       4.73  \n",
       "396             31.170       4.83  \n",
       "429             31.170       3.78  \n",
       "1               24.420       2.76  \n",
       "34              22.460       3.32  \n",
       "67              29.460       3.12  \n",
       "100             23.570       3.29  \n",
       "133             26.270       1.39  \n",
       "166             27.781       2.13  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"--- Step 3: Engineering new features ---\")\n",
    "\n",
    "# Feature 1: over_age_gap\n",
    "if 'COBERTURA_BRUTA' in df.columns and 'COBERTURA_NETA' in df.columns:\n",
    "    df['over_age_gap'] = df['COBERTURA_BRUTA'] - df['COBERTURA_NETA']\n",
    "    print(\"Created 'over_age_gap' feature.\")\n",
    "    print(f\"  Mean: {df['over_age_gap'].mean():.2f}, Std: {df['over_age_gap'].std():.2f}\")\n",
    "\n",
    "# Feature 2: repitencia_lag_1\n",
    "if 'REPITENCIA' in df.columns:\n",
    "    # Sort data to ensure correct lagging within groups\n",
    "    df = df.sort_values(by=['CÓDIGO_DEPARTAMENTO', 'AÑO'])\n",
    "    df['repitencia_lag_1'] = df.groupby('CÓDIGO_DEPARTAMENTO')['REPITENCIA'].shift(1)\n",
    "    print(\"Created 'repitencia_lag_1' (lagged repetition) feature.\")\n",
    "    print(f\"  NaN values created: {df['repitencia_lag_1'].isnull().sum()} (first year of each department)\")\n",
    "\n",
    "# Feature 3: classroom_density\n",
    "if 'TAMAÑO_PROMEDIO_DE_GRUPO' in df.columns:\n",
    "    df = df.rename(columns={'TAMAÑO_PROMEDIO_DE_GRUPO': 'classroom_density'})\n",
    "    print(\"Renamed 'TAMAÑO_PROMEDIO_DE_GRUPO' to 'classroom_density'.\")\n",
    "\n",
    "print(\"\\nFeature engineering complete.\")\n",
    "print(\"\\nSample of new features:\")\n",
    "display(df[['AÑO', 'DEPARTAMENTO', 'over_age_gap', 'REPITENCIA', 'repitencia_lag_1', 'classroom_density', 'DESERCIÓN']].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Leakage Prevention & Final Cleaning\n",
    "\n",
    "To prevent our model from \"cheating,\" we must remove any columns that would give away the answer (`DESERCIÓN`). These include:\n",
    "- `APROBACIÓN` (Approval Rate) and its sub-columns.\n",
    "- `REPROBACIÓN` (Failure Rate) and its sub-columns.\n",
    "\n",
    "Additionally, creating a lagged feature introduces `NaN` values for the first year of each department's data. These rows are now unusable and must be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 4: Preventing data leakage ---\n",
      "Identified 10 leakage columns:\n",
      "['APROBACIÓN', 'APROBACIÓN_TRANSICIÓN', 'APROBACIÓN_PRIMARIA', 'APROBACIÓN_SECUNDARIA', 'APROBACIÓN_MEDIA', 'REPROBACIÓN', 'REPROBACIÓN_TRANSICIÓN', 'REPROBACIÓN_PRIMARIA', 'REPROBACIÓN_SECUNDARIA', 'REPROBACIÓN_MEDIA']\n",
      "\n",
      "Dropped 10 leakage columns.\n",
      "Dropped 33 rows with NaN values from lagged features.\n",
      "\n",
      "Leakage prevention and final cleaning complete.\n",
      "Final dataset shape before splitting: (429, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Step 4: Preventing data leakage ---\")\n",
    "\n",
    "# Find and drop all columns related to approval and failure rates\n",
    "leakage_cols = [col for col in df.columns if 'APROBACIÓN' in col or 'REPROBACIÓN' in col]\n",
    "print(f\"Identified {len(leakage_cols)} leakage columns:\")\n",
    "print(leakage_cols[:10])  # Show first 10\n",
    "df = df.drop(columns=leakage_cols)\n",
    "print(f\"\\nDropped {len(leakage_cols)} leakage columns.\")\n",
    "\n",
    "# Drop rows with NaN values created by the lagging process\n",
    "initial_rows = len(df)\n",
    "df.dropna(subset=['repitencia_lag_1'], inplace=True)\n",
    "print(f\"Dropped {initial_rows - len(df)} rows with NaN values from lagged features.\")\n",
    "\n",
    "print(\"\\nLeakage prevention and final cleaning complete.\")\n",
    "print(f\"Final dataset shape before splitting: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Final Preparation & Verification\n",
    "\n",
    "Finally, we'll:\n",
    "1.  **Verify Signal:** Check the correlation between our newly engineered features and the target variable `DESERCIÓN`. This helps confirm that our new features are indeed related to the dropout rate.\n",
    "2.  **Prepare `X` and `y`:** Split the data into our final features matrix (`X`) and the target vector (`y`), ready for training a machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 6: Training the Optimized Model ---\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     12\u001b[39m predictors = [\n\u001b[32m     13\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mover_age_gap\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m     14\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mrepitencia_lag_1\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mCÓDIGO_DEPARTAMENTO\u001b[39m\u001b[33m'\u001b[39m  \u001b[38;5;66;03m# Ensure this column is in your df_final!\u001b[39;00m\n\u001b[32m     18\u001b[39m ]\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Verify these columns exist\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m available_predictors = [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m predictors \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf_final\u001b[49m.columns]\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining with features: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavailable_predictors\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     24\u001b[39m X = df_final[available_predictors]\n",
      "\u001b[31mNameError\u001b[39m: name 'df_final' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "print(\"--- Step 6: Training the Optimized Model ---\")\n",
    "\n",
    "# 1. SELECT ONLY THE BEST FEATURES\n",
    "# We discard the raw 'Cobertura' columns because 'over_age_gap' captures their essence better.\n",
    "# We keep Department ID because geography matters.\n",
    "predictors = [\n",
    "    'over_age_gap', \n",
    "    'repitencia_lag_1', \n",
    "    'classroom_density', \n",
    "    'POBLACIÓN_5_16', \n",
    "    'CÓDIGO_DEPARTAMENTO'  # Ensure this column is in your df_final!\n",
    "]\n",
    "\n",
    "# Verify these columns exist\n",
    "available_predictors = [col for col in predictors if col in df_final.columns]\n",
    "print(f\"Training with features: {available_predictors}\")\n",
    "\n",
    "X = df_final[available_predictors]\n",
    "y = df_final['DESERCIÓN']\n",
    "\n",
    "# 2. SPLIT DATA\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. TRAIN RANDOM FOREST\n",
    "# n_estimators=200: More trees = smoother predictions\n",
    "rf_model = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 4. EVALUATE\n",
    "y_pred = rf_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"\\nModel MAE: {mae:.4f} (Average prediction error in % points)\")\n",
    "\n",
    "# 5. VISUALIZE: ACTUAL vs PREDICTED (The \"Blob\" Check)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test, y=y_pred, alpha=0.6)\n",
    "plt.plot([0, y_test.max()], [0, y_test.max()], 'r--', lw=2) # Perfect prediction line\n",
    "plt.xlabel('Actual Dropout Rate (%)')\n",
    "plt.ylabel('Predicted Dropout Rate (%)')\n",
    "plt.title('Actual vs Predicted: Did we fix the blob?')\n",
    "plt.show()\n",
    "\n",
    "# 6. VISUALIZE: FEATURE IMPORTANCE (The \"Why\")\n",
    "importances = rf_model.feature_importances_\n",
    "feature_df = pd.DataFrame({'Feature': available_predictors, 'Importance': importances})\n",
    "feature_df = feature_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_df, hue='Feature', palette='viridis')\n",
    "plt.title('What actually drives Dropout?')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "✅ **Data Cleaning:** Converted percentage strings to numeric, dropped corrupt column  \n",
    "✅ **Imputation:** Handled missing values intelligently using departmental medians  \n",
    "✅ **Feature Engineering:** Created 3 \"Golden Features\" based on domain expertise  \n",
    "✅ **Leakage Prevention:** Removed all columns that could leak the target  \n",
    "✅ **Ready for Training:** Final X and y dataframes prepared for Random Forest Regressor\n",
    "\n",
    "---\n",
    "\n",
    "**Next Steps:**\n",
    "- Train a Random Forest Regressor using `X` and `y`\n",
    "- Evaluate model performance with cross-validation\n",
    "- Analyze feature importance to understand dropout drivers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
